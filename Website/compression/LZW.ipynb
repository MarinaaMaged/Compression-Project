{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"Reads the content of a file and returns it as a string.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    \"\"\"Writes the given content to a file.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def lzw_compression(data,output_path=\"output.txt\"):\n",
    "\n",
    "  if not data:\n",
    "    return [], 0\n",
    "    \n",
    "  # Initialize ASCII dictionary\n",
    "  ascii_dict = dict(map(lambda i: (chr(i), i), range(128)))\n",
    "\n",
    "  current_sequence = \"\"\n",
    "  compressed = list()\n",
    "  next_code = 128\n",
    "  \n",
    "  # Compression process\n",
    "  for next_char in data:\n",
    "    new_sequence = current_sequence + next_char\n",
    "    if(new_sequence in ascii_dict):\n",
    "      current_sequence = new_sequence\n",
    "    else : \n",
    "      compressed.append(ascii_dict[current_sequence])\n",
    "      ascii_dict[new_sequence] = next_code\n",
    "      next_code +=1\n",
    "      current_sequence = next_char\n",
    "\n",
    "  # Add the last sequence to the output\n",
    "  if current_sequence:\n",
    "    compressed.append(ascii_dict[current_sequence])\n",
    "\n",
    "  # Calculate the compression ratio\n",
    "  if compressed:\n",
    "    bit_length = math.ceil(math.log2(max(compressed) + 1))\n",
    "    CR = (len(data) * 8) / (len(compressed) * bit_length)\n",
    "  else:\n",
    "    CR = 0\n",
    "  write_file(output_path, str(compressed))\n",
    "  print(f\"Encoded text written to '{output_path}'.\")\n",
    "  return compressed , CR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_compression_savings(original_data, compressed_data):\n",
    "  original_bits = len(original_data) * 8\n",
    "  compressed_bits = len(compressed_data) * math.ceil(math.log2(max(compressed_data) + 1))\n",
    "  savings = (1 - compressed_bits / original_bits) * 100\n",
    "  return savings\n",
    "\n",
    "def calculate_average_bits_per_symbol(data, compressed):\n",
    "  if not data or not compressed:\n",
    "    return 0  # No symbols or compression\n",
    "  total_bits = len(compressed) * math.ceil(math.log2(max(compressed) + 1))\n",
    "  return total_bits / len(data)\n",
    "\n",
    "\n",
    "def calculate_entropy(data):\n",
    "  freq = Counter(data)\n",
    "  total_symbols = len(data)\n",
    "  probabilities = [count / total_symbols for count in freq.values()]\n",
    "  entropy = -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
    "  return entropy\n",
    "\n",
    "def calculate_compression_efficiency(original_data, compressed_data):\n",
    "  compressed_entropy = calculate_entropy(original_data)\n",
    "  average_bits = calculate_average_bits_per_symbol(original_data, compressed_data)\n",
    "  return (compressed_entropy / average_bits) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text written to 'output.txt'.\n",
      "Tag : [65, 66, 65, 128, 128, 129, 131, 134, 130, 129, 66, 138, 139, 138]\n",
      "the compression ratio: 2.0\n",
      "the compression entropy: 0.996316519558962\n",
      "Compression Savings: 50.0\n",
      "Average Bits per Symbol: 4.0\n",
      "Efficincy of the LZW algorithm: 24.90791298897405\n"
     ]
    }
   ],
   "source": [
    "file_path = input(\"Enter the file path you want to compress: \")\n",
    "compression_data = read_file(file_path)\n",
    "compressed , compression_ratio = lzw_compression(compression_data)\n",
    "savings = calculate_compression_savings(compression_data,compressed)\n",
    "avg_bits = calculate_average_bits_per_symbol(compression_data,compressed)\n",
    "entropy = calculate_entropy(compression_data)\n",
    "efficincy = calculate_compression_efficiency(compression_data,compressed)\n",
    "print(\"Tag :\",compressed)\n",
    "print(\"the compression ratio:\",compression_ratio)\n",
    "print(\"the compression entropy:\", entropy)\n",
    "print(\"Compression Savings:\", savings)\n",
    "print(\"Average Bits per Symbol:\", avg_bits)\n",
    "print(\"Efficincy of the LZW algorithm:\",efficincy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def lzw_decompress(compressed_data,output_path=\"input.txt\"):\n",
    "  if not compressed_data:\n",
    "    print(\"Error: No data to decompress.\")\n",
    "    return \"\"\n",
    "\n",
    "  # Initialize ASCII dictionary\n",
    "  ascii_dict = dict(map(lambda i: (i, chr(i)), range(128)))\n",
    "  dict_size = 128\n",
    "\n",
    "  if isinstance(compressed_data, str):\n",
    "    compressed_data = ast.literal_eval(compressed_data)\n",
    "    if isinstance(compressed_data,tuple):\n",
    "        compressed_data = list(compressed_data)\n",
    "\n",
    "  # Initialize decompression variables\n",
    "  current_code = compressed_data.pop(0)\n",
    "  pre_string = ascii_dict[current_code]\n",
    "  decompressed_data = [pre_string]\n",
    "\n",
    "  for code in compressed_data:\n",
    "    if code in ascii_dict:\n",
    "      current = ascii_dict[code]\n",
    "    elif code == dict_size:\n",
    "      current = pre_string + pre_string[0]\n",
    "    else:\n",
    "      raise ValueError(\"Invalid compressed data.\")\n",
    "\n",
    "    decompressed_data.append(current)\n",
    "\n",
    "    # Add new sequence to the dictionary\n",
    "    ascii_dict[dict_size] = pre_string + current[0]\n",
    "    dict_size += 1\n",
    "\n",
    "    pre_string = current\n",
    "  decompressed_text = \"\".join(decompressed_data)\n",
    "  write_file(output_path, decompressed_text)\n",
    "  print(f\"decompressed text written to '{output_path}'.\")\n",
    "  return \"\".join(decompressed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decompressed text written to 'input.txt'.\n",
      "Decompressed Data: ABAABABBAABAABAAAABABBBBBBBB\n"
     ]
    }
   ],
   "source": [
    "file_path = input(\"Enter the file path you want to decompress: \")\n",
    "data = read_file(file_path)\n",
    "decompressed = lzw_decompress(data)\n",
    "print(\"Decompressed Data:\", decompressed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
